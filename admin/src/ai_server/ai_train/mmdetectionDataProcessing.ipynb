{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a98799",
   "metadata": {},
   "source": [
    "### í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc6b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import easyocr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd3c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/pepsi/Downloads/mmdetection_data\"\n",
    "json_dir = glob.glob(root_dir + \"/*.json\")\n",
    "xml_dir = glob.glob(root_dir + \"/*.xml\")\n",
    "image_dir = glob.glob(root_dir + \"/*.png\")\n",
    "output_dir = \"/home/pepsi/Downloads/output\"\n",
    "split_ratio = 0.8\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619fe3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = output_dir + \"/images/train\"\n",
    "val_img_dir = output_dir + \"/images/val\"\n",
    "\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(val_img_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4891b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"ë³´í–‰ì\": 0,\n",
    "    \"í•‘í‚¤\": 1,\n",
    "    \"30ì œí•œ\": 2,\n",
    "    \"60ì œí•œ\": 3,\n",
    "    \"ì •ì§€ì„ \": 4,\n",
    "    \"íš¡ë‹¨ë³´ë„\": 5,\n",
    "    \"ë¹¨ê°„ë¶ˆ\": 6,\n",
    "    \"ë…¸ë€ë¶ˆ\": 7,\n",
    "    \"ì´ˆë¡ë¶ˆ\": 8\n",
    "}\n",
    "\n",
    "coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [{\"id\": v, \"name\": k} for k, v in label_map.items()]\n",
    "}\n",
    "\n",
    "image_id = 1\n",
    "annotation_id = 1\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155e4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7104/7104 [00:02<00:00, 2384.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ JSON ì²˜ë¦¬ (LabelMe + AIHub)\n",
    "for json_path in tqdm(json_dir):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if \"annotations\" in data:  # AIHub\n",
    "        file_name = data[\"filename\"]\n",
    "        width = int(data[\"camera\"][\"resolution_width\"])\n",
    "        height = int(data[\"camera\"][\"resolution_height\"])\n",
    "        annotations = data[\"annotations\"]\n",
    "\n",
    "    elif \"shapes\" in data:  # LabelMe\n",
    "        file_name = data[\"imagePath\"]\n",
    "        width = int(data.get(\"imageWidth\", 1920))\n",
    "        height = int(data.get(\"imageHeight\", 1080))\n",
    "        annotations = data[\"shapes\"]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    coco[\"images\"].append({\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": file_name,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    })\n",
    "\n",
    "    for ann in annotations:\n",
    "        label = ann.get(\"label\")\n",
    "        if label not in label_map:\n",
    "            continue\n",
    "\n",
    "        pts = ann[\"points\"]\n",
    "        x = [p[0] for p in pts]\n",
    "        y = [p[1] for p in pts]\n",
    "        xmin, xmax = min(x), max(x)\n",
    "        ymin, ymax = min(y), max(y)\n",
    "        w, h = xmax - xmin, ymax - ymin\n",
    "\n",
    "        coco[\"annotations\"].append({\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": label_map[label],\n",
    "            \"bbox\": [xmin, ymin, w, h],\n",
    "            \"area\": w * h,\n",
    "            \"iscrowd\": 0\n",
    "        })\n",
    "        annotation_id += 1\n",
    "    image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c84f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 877/877 [00:37<00:00, 23.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ XML ì²˜ë¦¬ (VOC)\n",
    "for xml_path in tqdm(xml_dir):\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "    file_name = root.findtext(\"filename\")\n",
    "    width = int(root.find(\"size/width\").text)\n",
    "    height = int(root.find(\"size/height\").text)\n",
    "\n",
    "    coco[\"images\"].append({\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": file_name,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    })\n",
    "\n",
    "    image_path = root_dir + \"/\" + file_name\n",
    "    image = cv2.imread(str(image_path))\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.findtext(\"name\")\n",
    "        if name == \"speedlimit\":\n",
    "            box = obj.find(\"bndbox\")\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            cropped = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            if cropped is None or cropped.size == 0 or cropped.shape[0] < 5 or cropped.shape[1] < 5:\n",
    "                continue\n",
    "            \n",
    "            results = reader.readtext(cropped)\n",
    "            detected_text = ''.join([res[1] for res in results])\n",
    "\n",
    "            if \"60\" in detected_text:\n",
    "                label = \"60ì œí•œ\"\n",
    "            elif \"30\" in detected_text:\n",
    "                label = \"30ì œí•œ\"\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue  # ë‹¤ë¥¸ ë¼ë²¨ì€ ë¬´ì‹œ\n",
    "\n",
    "        w, h = xmax - xmin, ymax - ymin\n",
    "        coco[\"annotations\"].append({\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": label_map[label],\n",
    "            \"bbox\": [xmin, ymin, w, h],\n",
    "            \"area\": w * h,\n",
    "            \"iscrowd\": 0\n",
    "        })\n",
    "        annotation_id += 1\n",
    "\n",
    "    image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b53cb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¸ 8:2 train/val ë¶„ë¦¬\n",
    "random.shuffle(coco[\"images\"])\n",
    "split_idx = int(len(coco[\"images\"]) * split_ratio)\n",
    "train_imgs = coco[\"images\"][:split_idx]\n",
    "val_imgs = coco[\"images\"][split_idx:]\n",
    "\n",
    "train_ids = {img[\"id\"] for img in train_imgs}\n",
    "val_ids = {img[\"id\"] for img in val_imgs}\n",
    "train_anns = [a for a in coco[\"annotations\"] if a[\"image_id\"] in train_ids]\n",
    "val_anns = [a for a in coco[\"annotations\"] if a[\"image_id\"] in val_ids]\n",
    "\n",
    "# ğŸ”¸ JSON ì €ì¥\n",
    "with open(output_dir + \"/test/train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"images\": train_imgs, \"annotations\": train_anns, \"categories\": coco[\"categories\"]}, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(output_dir + \"/test/val.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"images\": val_imgs, \"annotations\": val_anns, \"categories\": coco[\"categories\"]}, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "170b1d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6384/6384 [01:18<00:00, 81.27it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1597/1597 [00:23<00:00, 69.18it/s] \n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¸ ì´ë¯¸ì§€ ë³µì‚¬\n",
    "def copy_images(image_list, dest_dir):\n",
    "    for img in tqdm(image_list):\n",
    "        src = \"/home/pepsi/Downloads/mmdetection_data/\" + img[\"file_name\"]\n",
    "        dst = dest_dir + \"/\" + img[\"file_name\"]\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "copy_images(train_imgs, train_img_dir)\n",
    "copy_images(val_imgs, val_img_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "addin-taxi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
